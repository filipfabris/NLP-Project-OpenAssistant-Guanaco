# NLPProject-OpenAssistant-Guanaco
This is a repository for the project OpenAssistant-Guanaco of the Natural Language Processing course given by prof. Carman Mark James

## Team Members

- Balice Matteo (10978268)

- Doronzo Antonio Giuseppe (11016435)

- Fabris Filip (10986123)

- Masini Alessandro (10940986)


## Project Description
Fine tuned LLMA3 8B model on the Guanaco dataset. The Guanaco dataset is a collection of 1000 dialogues between a user and a virtual assistant. The dataset is composed of 1000 dialogues, each of which is composed of 10 turns. Each turn is composed of a user message and a system response. The dataset is divided into training, validation and test set. The training set is composed of 800 dialogues, the validation set is composed of 100 dialogues and the test set is composed of 100 dialogues. The goal of the project is to fine tune the LLMA3 8B model on the Guanaco dataset and evaluate the performance of the model on the test set. The evaluation will be done by computing the BLEU score between the system responses generated by the model and the ground truth system responses in the test set.

## Gradio Application
Created a Gradio application that allows the user to interact with the fine tuned LLMA3 8B model on the Guanaco dataset. The application is composed of a text box where the user can input a message and a text box where the system response generated by the model is displayed. The user can input a message in the text box and press the submit button to get the system response generated by the model. The system response is displayed in the text box below the submit button.

## How to run the Gradio Application
It allows audio and text input and generates text output along with the audio output. 

The application is contained jupyter notebook file `gradio_app.ipynb` which can be run on Google Colab. The notebook contains the code to load the fine tuned LLMA3 8B model on the Guanaco dataset and create the Gradio application. 

It is composed inside google colab notebook because T4 GPU is required to run the model and generate the responses in a reasonable time.
